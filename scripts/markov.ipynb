{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_markov_chain(data, k=1):\n",
    "    model = {}\n",
    "    for sequence in data:\n",
    "        for i in range(len(sequence) - k):\n",
    "            kmer = sequence[i:i+k]\n",
    "            next_base = sequence[i+k]\n",
    "            if kmer not in model:\n",
    "                model[kmer] = []\n",
    "            model[kmer].append(next_base)\n",
    "    return model\n",
    "\n",
    "def generate_sequence(markov_model, length=100):\n",
    "    current_kmer = random.choice(list(markov_model.keys()))\n",
    "    k = len(current_kmer)\n",
    "    generated_sequence = current_kmer\n",
    "    for _ in range(length - k):\n",
    "        if current_kmer not in markov_model: # if the current kmer is not in the model (e.g., it was at the end of a sequence in the data), choose a random kmer\n",
    "            current_kmer = random.choice(list(markov_model.keys()))\n",
    "        possible_bases = markov_model[current_kmer]\n",
    "        next_base = random.choice(possible_bases)\n",
    "        generated_sequence += next_base\n",
    "        current_kmer = current_kmer[1:] + next_base\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data as list of sequence strings\n",
    "#data_loc = \"../data/prom400\"\n",
    "data_loc = \"../data/human\"\n",
    "train_set_loc = data_loc + '/train.txt'\n",
    "with open(train_set_loc) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# Train the Markov chain model\n",
    "max_k = 6\n",
    "markov_models = {}\n",
    "for k in range(1, max_k+1):\n",
    "    markov_models[k] = train_markov_chain(lines, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequence samples\n",
    "sample_folder = data_loc + '/markovBaseline'\n",
    "batch_num = 2\n",
    "batch_size = 64\n",
    "for k in markov_models:\n",
    "    with open(os.path.join(sample_folder, f\"{k}.txt\"), \"w\") as f:\n",
    "        for _ in range(batch_num * batch_size):\n",
    "            generated_sequence = generate_sequence(markov_models[k], length=300)\n",
    "            f.write(generated_sequence + \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5524777f9ae87ee981d4a77d29becedd5dda7e9b58ee4fd8ecba0dbab17f824f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
